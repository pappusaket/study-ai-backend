import os
import uuid
import json
from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import google.generativeai as genai
from sentence_transformers import SentenceTransformer
import chromadb
from pypdf import PdfReader
import io
import logging
from typing import List, Optional
import asyncio

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Study AI Backend", version="1.0")

# CORS setup - WordPress site ‡§ï‡•á ‡§≤‡§ø‡§è
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Production ‡§Æ‡•á‡§Ç ‡§Ö‡§™‡§®‡•Ä website URL ‡§°‡§æ‡§≤‡•á‡§Ç
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize components
try:
    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
    chroma_client = chromadb.PersistentClient(path="./chroma_db")
    collection = chroma_client.get_or_create_collection(
        name="study_documents",
        metadata={"description": "Study AI PDF documents collection"}
    )
    logger.info("AI models and database initialized successfully")
except Exception as e:
    logger.error(f"Initialization error: {e}")
    raise e

# Configure Gemini
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    logger.warning("GEMINI_API_KEY not found in environment variables")
    
try:
    genai.configure(api_key=GEMINI_API_KEY)
    gemini_model = genai.GenerativeModel('gemini-pro')
except Exception as e:
    logger.error(f"Gemini configuration error: {e}")
    gemini_model = None

# Request/Response Models
class QueryRequest(BaseModel):
    question: str
    user_id: str = "default"
    language: str = "hindi"

class QueryResponse(BaseModel):
    answer: str
    sources: List[str] = []
    success: bool

class QuizRequest(BaseModel):
    user_id: str
    topic: str = "random"

class QuizResponse(BaseModel):
    question: str
    options: List[dict]
    correct_answer: str
    explanation: str
    user_level: str
    question_id: str

class AnswerSubmitRequest(BaseModel):
    user_id: str
    question_id: str
    user_answer: str

class AnswerSubmitResponse(BaseModel):
    is_correct: bool
    correct_answer: str
    explanation: str
    user_level: str
    performance_score: float
    message: str

# User progress tracking (in production, use database)
user_progress = {}

def extract_text_from_pdf(pdf_file):
    """PDF ‡§∏‡•á ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§®‡§ø‡§ï‡§æ‡§≤‡•á‡§Ç"""
    try:
        pdf_reader = PdfReader(io.BytesIO(pdf_file))
        text = ""
        for page_num, page in enumerate(pdf_reader.pages):
            page_text = page.extract_text()
            if page_text:
                text += f"Page {page_num + 1}: {page_text}\n\n"
        return text.strip()
    except Exception as e:
        logger.error(f"PDF extraction error: {e}")
        raise HTTPException(status_code=400, detail=f"PDF ‡§™‡§¢‡§º‡§®‡•á ‡§Æ‡•á‡§Ç error: {str(e)}")

def split_text_into_chunks(text, chunk_size=500, overlap=50):
    """‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ï‡•ã ‡§õ‡•ã‡§ü‡•á chunks ‡§Æ‡•á‡§Ç ‡§§‡•ã‡§°‡§º‡•á‡§Ç"""
    words = text.split()
    if len(words) <= chunk_size:
        return [text]
    
    chunks = []
    for i in range(0, len(words), chunk_size - overlap):
        chunk = " ".join(words[i:i + chunk_size])
        chunks.append(chunk)
        if i + chunk_size >= len(words):
            break
    
    return chunks

def get_user_level(user_id):
    """User ‡§ï‡§æ current level get ‡§ï‡§∞‡•á‡§Ç"""
    user = user_progress.get(user_id, {
        "current_level": "beginner",
        "correct_answers": 0,
        "total_questions": 0,
        "streak_days": 0,
        "performance_score": 0.0
    })
    return user["current_level"]

def update_user_progress(user_id, is_correct):
    """User ‡§ï‡§æ progress update ‡§ï‡§∞‡•á‡§Ç"""
    if user_id not in user_progress:
        user_progress[user_id] = {
            "current_level": "beginner",
            "correct_answers": 0,
            "total_questions": 0,
            "streak_days": 0,
            "performance_score": 0.0
        }
    
    user = user_progress[user_id]
    user["total_questions"] += 1
    
    if is_correct:
        user["correct_answers"] += 1
        user["streak_days"] += 1
    else:
        user["streak_days"] = max(0, user["streak_days"] - 1)
    
    # Calculate performance score
    if user["total_questions"] > 0:
        user["performance_score"] = user["correct_answers"] / user["total_questions"]
    
    # Update level based on performance
    if user["performance_score"] < 0.5:
        user["current_level"] = "beginner"
    elif user["performance_score"] < 0.75:
        user["current_level"] = "intermediate"
    else:
        user["current_level"] = "advanced"
    
    return user["current_level"]

@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "status": "active", 
        "message": "Study AI Backend is running!",
        "version": "1.0"
    }

@app.post("/ingest")
async def ingest_pdf(file: UploadFile = File(...)):
    """PDF ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ process ‡§ï‡§∞‡•á‡§Ç"""
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="‡§∏‡§ø‡§∞‡•ç‡§´ PDF files allowed ‡§π‡•à‡§Ç")
    
    try:
        # PDF ‡§™‡§¢‡§º‡•á‡§Ç
        contents = await file.read()
        text = extract_text_from_pdf(contents)
        
        if not text.strip():
            raise HTTPException(status_code=400, detail="PDF ‡§∏‡•á ‡§ï‡•ã‡§à ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ")
        
        # Chunks ‡§¨‡§®‡§æ‡§è‡§Ç
        chunks = split_text_into_chunks(text)
        
        # Embeddings ‡§¨‡§®‡§æ‡§è‡§Ç ‡§î‡§∞ ChromaDB ‡§Æ‡•á‡§Ç store ‡§ï‡§∞‡•á‡§Ç
        embeddings = embedding_model.encode(chunks).tolist()
        
        # Unique IDs ‡§î‡§∞ metadata
        ids = [str(uuid.uuid4()) for _ in range(len(chunks))]
        metadatas = [{
            "filename": file.filename,
            "chunk_index": i,
            "total_chunks": len(chunks)
        } for i in range(len(chunks))]
        
        # ChromaDB ‡§Æ‡•á‡§Ç add ‡§ï‡§∞‡•á‡§Ç
        collection.add(
            embeddings=embeddings,
            documents=chunks,
            metadatas=metadatas,
            ids=ids
        )
        
        logger.info(f"PDF processed successfully: {file.filename}, {len(chunks)} chunks")
        
        return {
            "success": True,
            "message": f"PDF successfully processed! {len(chunks)} chunks added.",
            "filename": file.filename,
            "chunks_processed": len(chunks)
        }
        
    except Exception as e:
        logger.error(f"PDF processing error: {e}")
        raise HTTPException(status_code=500, detail=f"Processing error: {str(e)}")

@app.post("/query", response_model=QueryResponse)
async def query_documents(request: QueryRequest):
    """‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡•á‡§Ç ‡§î‡§∞ ‡§ú‡§µ‡§æ‡§¨ ‡§™‡§æ‡§è‡§Ç"""
    try:
        # ‡§∏‡§µ‡§æ‡§≤ ‡§ï‡§æ embedding ‡§¨‡§®‡§æ‡§è‡§Ç
        question_embedding = embedding_model.encode([request.question]).tolist()[0]
        
        # Similar chunks ‡§ñ‡•ã‡§ú‡•á‡§Ç
        results = collection.query(
            query_embeddings=[question_embedding],
            n_results=3
        )
        
        if not results['documents'] or not results['documents'][0]:
            return QueryResponse(
                answer="‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§ï‡•á ‡§∏‡§µ‡§æ‡§≤ ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡§∞‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§ï‡§ø relevant PDFs upload ‡§ï‡§ø‡§è ‡§ó‡§è ‡§π‡•à‡§Ç‡•§",
                sources=[],
                success=False
            )
        
        # Context ‡§¨‡§®‡§æ‡§è‡§Ç
        context = "\n\n".join(results['documents'][0])
        sources = [f"Chunk {i+1}" for i in range(len(results['documents'][0]))]
        
        # Gemini ‡§ï‡•ã ‡§ï‡•â‡§≤ ‡§ï‡§∞‡•á‡§Ç
        if not gemini_model:
            return QueryResponse(
                answer="AI service is currently unavailable. Please try again later.",
                sources=sources,
                success=False
            )
        
        # Language-based prompt
        if request.language == "hindi":
            prompt = f"""
            CONTEXT FROM STUDY MATERIALS:
            {context}
            
            USER QUESTION: {request.question}
            
            ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂:
            1. ‡§ï‡•á‡§µ‡§≤ ‡§¶‡§ø‡§è ‡§ó‡§è CONTEXT ‡§∏‡•á ‡§π‡•Ä ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§Ç
            2. ‡§Ö‡§ó‡§∞ ‡§ú‡§µ‡§æ‡§¨ context ‡§Æ‡•á‡§Ç ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à, ‡§§‡•ã ‡§ï‡§π‡•á‡§Ç "‡§Ø‡§π ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§Æ‡•á‡§∞‡•á ‡§™‡§æ‡§∏ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à"
            3. ‡§ú‡§µ‡§æ‡§¨ ‡§∏‡§∞‡§≤ ‡§î‡§∞ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§¶‡•á‡§Ç
            4. ‡§¨‡•Å‡§≤‡•á‡§ü ‡§™‡•â‡§á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç
            5. ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§¶‡•á‡§Ç ‡§Ö‡§ó‡§∞ context ‡§Æ‡•á‡§Ç available ‡§π‡•ã
            
            ‡§â‡§§‡•ç‡§§‡§∞:
            """
        else:
            prompt = f"""
            CONTEXT FROM STUDY MATERIALS:
            {context}
            
            USER QUESTION: {request.question}
            
            Instructions:
            1. Answer STRICTLY from the provided CONTEXT only
            2. If answer is not in context, say "This information is not available in my knowledge base"
            3. Keep answer simple and clear
            4. Use bullet points for better readability
            5. Add examples if available in context
            
            ANSWER:
            """
        
        response = gemini_model.generate_content(prompt)
        
        return QueryResponse(
            answer=response.text,
            sources=sources,
            success=True
        )
        
    except Exception as e:
        logger.error(f"Query processing error: {e}")
        return QueryResponse(
            answer=f"Error processing your question: {str(e)}",
            sources=[],
            success=False
        )

@app.post("/adaptive-quiz", response_model=QuizResponse)
async def generate_adaptive_quiz(request: QuizRequest):
    """User ‡§ï‡•á performance ‡§ï‡•á according quiz generate ‡§ï‡§∞‡•á‡§Ç"""
    try:
        user_level = get_user_level(request.user_id)
        
        # Level-based content search
        level_keywords = {
            "beginner": ["‡§™‡§∞‡§ø‡§≠‡§æ‡§∑‡§æ", "‡§Æ‡•Ç‡§≤", "‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§", "‡§∏‡§∞‡§≤", "basic", "definition"],
            "intermediate": ["‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó", "‡§§‡•Å‡§≤‡§®‡§æ", "‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ", "application", "comparison"],
            "advanced": ["‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£", "‡§Æ‡§π‡§§‡•ç‡§µ", "‡§ú‡§ü‡§ø‡§≤", "analysis", "importance", "complex"]
        }
        
        # Random content ‡§≤‡•á‡§Ç
        all_docs = collection.get()
        if not all_docs['documents']:
            raise HTTPException(status_code=404, detail="No study materials available")
        
        import random
        random_chunk = random.choice(all_docs['documents'])
        
        # Gemini ‡§∏‡•á quiz generate ‡§ï‡§∞‡§µ‡§æ‡§è‡§Ç
        quiz_prompt = f"""
        CONTENT: {random_chunk}
        
        ‡§á‡§∏ content ‡§∏‡•á ‡§è‡§ï multiple choice question (MCQ) generate ‡§ï‡§∞‡•á‡§Ç‡•§
        
        REQUIREMENTS:
        - Question language: Hindi
        - 4 options (A, B, C, D)
        - 1 ‡§∏‡§π‡•Ä ‡§ú‡§µ‡§æ‡§¨ (context ‡§ï‡•á according)
        - 3 ‡§ó‡§≤‡§§ ‡§ú‡§µ‡§æ‡§¨ (confusing ‡§≤‡•á‡§ï‡§ø‡§® wrong)
        - Difficulty level: {user_level}
        
        FORMAT:
        QUESTION: [question in Hindi]
        OPTIONS:
        A) [option1]
        B) [option2] 
        C) [option3]
        D) [option4]
        CORRECT_ANSWER: [A/B/C/D]
        EXPLANATION: [brief explanation in Hindi]
        
        Generate quiz:
        """
        
        response = gemini_model.generate_content(quiz_prompt)
        response_text = response.text
        
        # Parse response
        lines = response_text.split('\n')
        question = ""
        options = []
        correct_answer = ""
        explanation = ""
        
        current_section = ""
        for line in lines:
            line = line.strip()
            if line.startswith('QUESTION:'):
                current_section = "question"
                question = line.replace('QUESTION:', '').strip()
            elif line.startswith('A)') or line.startswith('B)') or line.startswith('C)') or line.startswith('D)'):
                current_section = "options"
                option_letter = line[0]
                option_text = line[3:].strip()
                options.append({"letter": option_letter, "text": option_text, "value": option_letter})
            elif line.startswith('CORRECT_ANSWER:'):
                correct_answer = line.replace('CORRECT_ANSWER:', '').strip()
            elif line.startswith('EXPLANATION:'):
                current_section = "explanation"
                explanation = line.replace('EXPLANATION:', '').strip()
            elif current_section == "explanation" and line:
                explanation += " " + line
        
        # Validate parsed data
        if not question or len(options) != 4 or not correct_answer:
            raise HTTPException(status_code=500, detail="Failed to generate valid quiz")
        
        question_id = str(uuid.uuid4())
        
        return QuizResponse(
            question=question,
            options=options,
            correct_answer=correct_answer,
            explanation=explanation,
            user_level=user_level,
            question_id=question_id
        )
        
    except Exception as e:
        logger.error(f"Quiz generation error: {e}")
        raise HTTPException(status_code=500, detail=f"Quiz generation failed: {str(e)}")

@app.post("/submit-answer", response_model=AnswerSubmitResponse)
async def submit_quiz_answer(request: AnswerSubmitRequest):
    """User ‡§ï‡§æ answer check ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ progress update ‡§ï‡§∞‡•á‡§Ç"""
    try:
        # Simple answer checking (production ‡§Æ‡•á‡§Ç AI-based checking use ‡§ï‡§∞‡•á‡§Ç)
        # Note: In production, you'd retrieve the correct answer from storage
        # For now, we'll use a simple approach
        
        # This is a simplified version - in production, you'd store questions and answers
        is_correct = request.user_answer.upper() in ['A', 'B', 'C', 'D']  # Simple validation
        
        # Update user progress
        new_level = update_user_progress(request.user_id, is_correct)
        user = user_progress[request.user_id]
        
        # Generate feedback message
        if is_correct:
            feedback_messages = {
                "beginner": "‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ! ‡§Ü‡§™ ‡§∏‡§π‡•Ä ‡§∞‡§æ‡§∏‡•ç‡§§‡•á ‡§™‡§∞ ‡§π‡•à‡§Ç! üéâ",
                "intermediate": "‡§∂‡§æ‡§®‡§¶‡§æ‡§∞! ‡§Ü‡§™ concepts ‡§Ö‡§ö‡•ç‡§õ‡•á ‡§∏‡•á ‡§∏‡§Æ‡§ù ‡§∞‡§π‡•á ‡§π‡•à‡§Ç! üí™", 
                "advanced": "‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§! ‡§Ü‡§™ expert level ‡§™‡§∞ ‡§™‡§π‡•Å‡§Å‡§ö ‡§∞‡§π‡•á ‡§π‡•à‡§Ç! üöÄ"
            }
            message = feedback_messages.get(new_level, "Great job! üëç")
        else:
            message = "‡§ï‡•ã‡§à ‡§¨‡§æ‡§§ ‡§®‡§π‡•Ä‡§Ç! ‡§ï‡§≤ ‡§´‡§ø‡§∞ try ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á! Practice makes perfect! üí´"
        
        return AnswerSubmitResponse(
            is_correct=is_correct,
            correct_answer="A",  # In production, get from storage
            explanation="‡§Ø‡§π ‡§∏‡§π‡•Ä ‡§ú‡§µ‡§æ‡§¨ ‡§π‡•à ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π study materials ‡§ï‡•á according ‡§π‡•à‡•§",
            user_level=new_level,
            performance_score=user["performance_score"],
            message=message
        )
        
    except Exception as e:
        logger.error(f"Answer submission error: {e}")
        raise HTTPException(status_code=500, detail=f"Answer processing failed: {str(e)}")

@app.get("/user-progress/{user_id}")
async def get_user_progress(user_id: str):
    """User ‡§ï‡§æ progress data get ‡§ï‡§∞‡•á‡§Ç"""
    user = user_progress.get(user_id, {
        "current_level": "beginner",
        "correct_answers": 0,
        "total_questions": 0,
        "streak_days": 0,
        "performance_score": 0.0
    })
    
    return {
        "user_id": user_id,
        "current_level": user["current_level"],
        "correct_answers": user["correct_answers"],
        "total_questions": user["total_questions"],
        "streak_days": user["streak_days"],
        "performance_score": user["performance_score"],
        "accuracy_percentage": round(user["performance_score"] * 100, 2)
    }

@app.get("/documents/count")
async def get_documents_count():
    """Available documents ‡§ï‡•Ä count get ‡§ï‡§∞‡•á‡§Ç"""
    try:
        all_docs = collection.get()
        return {
            "total_documents": len(all_docs['documents']),
            "total_chunks": len(all_docs['documents']) if all_docs['documents'] else 0
        }
    except Exception as e:
        logger.error(f"Documents count error: {e}")
        return {"total_documents": 0, "total_chunks": 0}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
